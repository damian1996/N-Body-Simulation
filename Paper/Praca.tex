\documentclass[14pt,twoside,a4paper]{article}
\usepackage{polski}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{bera}
\usepackage{blindtext}
%\usepackage{algorithm}
%\usepackage[noend]{algpseudocode}
\usepackage{caption}
\usepackage{esvect}
\usepackage{geometry}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{calc}
\usepackage{color}
\usepackage{fontenc}
\usepackage[document]{ragged2e}
\usepackage{bm}
\usepackage{pstricks}
\usepackage{tikz}
\usepackage{auto-pst-pdf}
\usepackage{pgfplots}
\pgfplotsset{compat=newest}
\usepackage{hyperref}
\usepackage[
backend=biber,
bibstyle=numeric,
citestyle=numeric,
]{biblatex}
\addbibresource{biblio.bib}
\hypersetup{
  colorlinks, linkcolor=blue, citecolor=red
}
\DeclareCaptionFont{white}{\color{white}}
\DeclareCaptionFormat{listing}{\colorbox{gray}{\parbox{\textwidth}{#1#2#3}}}
\definecolor{mygreen}{rgb}{0,0.6,0}
\captionsetup[lstlisting]{format=listing,labelfont=white,textfont=white}
\newtheorem{theorem}{Prawo}
\newenvironment{myproof}[2] {\paragraph{Dowód:}}{\hfill$\square$}
\newcommand\tab[1][1cm]{\hspace*{#1}}

\theoremstyle{definition}
\newtheorem{definition}{Definicja}[section]

%\geometry{left=2.5cm,right=2.5cm,top=10.0cm,bottom=2.5cm}
\begin{document}

\begin{titlepage}
	\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}
	
	\center
	
	\textsc{\Large Uniwersytet  Jagielloński\\
			 Wydział Matematyki i Informatyki\\
    		 Zespół Katedr i Zakładów Informatyki Matematycznej}\\[1.5cm]
	
	\textsc{\Large}\\[0.5cm]
	
	\textsc{\Large}\\[0.5cm]
	
	\HRule\\[0.4cm]
		
	{\huge\bfseries Wielowątkowa symulacja N ciał z implementacją w architekturze CUDA}\\[0.4cm] % Title 
	
	\HRule\\[1.5cm]
	
	\begin{minipage}{0.4\textwidth}
		\begin{flushleft}
			\large
			\textit{Autor}\\
			Damian Stachura% \textsc{Stachura}  Your name
		\end{flushleft}
	\end{minipage}
	~
	\begin{minipage}{0.4\textwidth}
		\begin{flushright}
			\large
			\textit{Opiekun}\\
			dr Maciej Ślusarek %\textsc{Ślusarek}  Supervisor's name
		\end{flushright}
	\end{minipage}
	
	\vfill\vfill % Position the date 3/4 down the remaining page
	
	{\large\today} % Date, change the \today to a set date if you want to be precise
	
\end{titlepage}

\newpage
\tableofcontents

\newpage

\section{\LARGE Przedstawienie problemu symulacji N ciał}
\bigskip
Symulacja N ciał jest zagadnieniem z mechaniki klasycznej, które polega na wyznaczeniu toru ruchów wszystkich ciał danego układu o danych masach, prędkościach i położeniach początkowych w oparciu o prawa ruchu i założenie, że ciała oddziałują ze sobą zgodnie z prawem grawitacji Newtona. \\ 
Podstawowe zagadnienia do symulacji N ciał zostały przedstawione przez \textbf{Isaaca Newtona} w 1687 roku, który wprowadził prawa(później zostaną przedstawione dokładniej), które obowiązują przy próbach analitycznego rozwiązania problemu. \cite{Principia}. Początki symulacji można datować na rok 1941, kiedy to \textbf{Erik Holmberg}, prowadził eksperymenty z galaktykami, które modelował jako okręgi, w których punkty koncetrowały się wokół wspólnego środka. Co ciekawe, w swoich eksperymentach reprezentował punkty w galaktyce poprzez żarówki. \cite{holmberg} Z kolei pierwsze obliczenia dla symulacji N ciał na komputerze zostały wykonane przez \textbf{Sebastiana von Hoernera} w 1960 roku. \cite{vonHoerner}

\subsection{\Large Szczególne przypadki}
Problem analitycznego wyznaczenia dokładnego ruchu dowolnej liczby ciał jest trudny, więc można znaleźć wiele prac skupiająych się jedynie na ustalonej, małej liczbie ciał.

\subsubsection{\large Problem dwóch ciał}
Problem dla dwóch ciał podlegających prawom klasycznej dynamiki Newtona i przyciągających się zgodnie z newtonowskim prawem powszechnego ciążenia został analitycznie rozstrzygnięty przez J. Bernoulliego przy założeniu, że masa obiektu koncentruje się w jego środku. \cite[str.~1-49]{fund}

Obydwa ciała poruszają się po krzywych stożkowych, których rodzaj zależy od całkowitej energii układu. Przykładowo, gdy energia jest mała, to ciała nie mogą się od siebie uwolnić, więc krążą wokół siebie po elipsach.

\subsubsection{\large Problem trzech ciał}
Problem trzech ciał wciąż nie został rozwiązany analitycznie w ogólności. Jednakże istnieją rozwiązania dla uproszczonych wersji tego problemu, jak na przykład gdy masy obiektów są równe \cite{threebody1} lub w przypadku gdy w układzie mamy trzy równoległe względem siebie linie, a każde z ciał porusza się po jednej z prostych \cite{threebody2}, a także gdy masa jednego z ciał obecnych w systemi jest zaniedbywalnie mała(jest to tak zwany ograniczony problem trzech ciał - przedstawiony przez J. L. Lagrange'a w XVIII wieku) \cite{szebehely}.

\subsection{\Large Zastosowania}
Symulacje N ciał są szeroko wykorzystywanymi narzędziami w fizyce oraz astronomii. Problemem, w którym symulacje są użyteczne jest na przykład dynamika systemu z kilkoma ciałami jak układ Słońce-Ziemia-Księżyc \cite{SEMmisc} lub dynamika systemów gwiezdnych \cite{chaosMisc}.\\
W kosmologii symulacje są wykorzystywane do studiowania procesów tworzenia nieliniowych struktur jak galaktyczne halo z wpływem ciemnej materii \cite{haloDensity}. 
Z kolei, bezpośrednie symulacje N ciał są wykorzystywane na przykład do studiowania dynamicznej ewolucji klastrów gwiazd lub do symulacji dynamiki planetozymali. \cite{dirNBody}. Zastosowania symulacji można zaobserwować również w innych dziedzinach, chociażby w algorytmach rysowania grafu skierowanego metodą siłową (ang. force-directed graph drawing) \cite{visGraph}. Powyższe przykłady pokazują jak różnorodny jest zakres zastosowań symulacji.

\subsection{\Large Implementacja i wykorzystane technologie}
W pierwszej części mojej pracy przedstawię równoległą implementację naiwnego algorytmu symulacji N ciał. W każdym kroku algorytm bezpośrednio wyznacza siły oddziałujące wzajemnie pomiędzy każdymi dwoma ciałami w systemie, przez co oblicza całkowitą siłę oddziałującą na każde ciało w jednym kroku symulacji. W drugiej części zaimplementuję wielowątkowo algorytm Barnesa-Huta, który korzysta z drzew ósemkowych.

Repozytorium z całym kodem projektu jest dostępne pod tym \href{https://github.com/damian1996/N-Body-Simulation}{adresem}.
Całość została zaimplementowana w C++. Innymi technologiami wykorzystanymi w pracy są OpenGL, CUDA czy Thrust, których zastosowanie zostanie wspomniane później. \\
Pełna instrukcja instalacji niezbędnego oprogramowania do uruchomienia symulacji jest zawarta w repozytorium (dla linuxa Ubuntu).

\section{\LARGE Teoretyczne podstawy symulacji N ciał}

W celu przedstawienia ogólnego sformułowania problemu potrzebujemy przytoczyć trzy prawa dynamiki sformułowane przez Isaaca Newtona \cite[str.~83-84]{Principia} :

\begin{theorem}
W inercjalnym układzie odniesienia, jeśli na ciało nie działa żadna siła lub siły działające równoważą się, to ciało pozostaje w spoczynku lub porusza się ruchem jednostajnym prostoliniowym.
\end{theorem}

\begin{theorem}
W inercjalnym układzie odniesienia jeśli siły działające na ciało nie równoważą się (czyli wypadkowa sił ${\vec{F}}_{w}$ jest różna od zera), to ciało porusza się z przyspieszeniem wprost proporcjonalnym do siły wypadkowej, a odwrotnie proporcjonalnym do masy ciała.
\end{theorem}
Co oznacza, że w inercjalnym układzie odniesienia zachodzi równość $F=ma$, gdzie $F$ jest sumą sił działających na obiekt, $m$ to masa obiektu, $a$ to jego przyśpieszenie.

\begin{theorem}
Oddziaływania ciał są zawsze wzajemne. W inercjalnym układzie odniesienia siły wzajemnego oddziaływania dwóch ciał mają takie same wartości, taki sam kierunek, przeciwne zwroty i różne punkty przyłożenia (każda działa na inne ciało).
\end{theorem} 

Niezbędne jest również przytoczenie prawa powszechnego ciążenia Newtona \cite[str.956]{fund}
\begin{theorem}
Między dowolną parą ciał posiadających masy pojawia się siła przyciągająca, która działa na linii łączącej ich środki, a jej wartość rośnie z iloczynem ich mas i maleje z kwadratem odległości.
\end{theorem}

Aplikując to prawo do symulacji N ciał, uzyskujemy że na $i$-te ciało działa siła $F_i$ zdefiniowana następująco:\\
$$F_i = -G\cdot m_i \sum_{j=1, j\neq i}^N \frac{m_j(r_i - r_j)}{|r_i - r_j|^3},$$gdzie $m_i$ to masa ciała na które oddziałują inne ciała, $m_j$ to masa ciała oddziałującego na $i$-te ciało, $r_i - r_j$ to różnica wektorów pozycji dwóch ciał, $|r_i - r_j|$ to dystans między ciałami, a $G$ to stała grawitacji i wynosi
\begin{center}
$$G = 6,67408(31)\cdot 10^{-11} \frac{m^{3}}{kg s^2}.$$
\end{center}
Z wykorzystaniem powyższych praw możemy podać następującą definicję
\paragraph{Symulacja N ciał} 
\newcommand{\mi}{\boldsymbol{} \mathrel{\mkern -16mu} \boldsymbol{-}}
$\mi$
Dla N ciał mających ustalone masy oraz początkowe położenie i prędkość, ruch każdego obiektu jest symulowany z wykorzystaniem prawa powszechnego ciążenia oraz poprzez wyznaczenie przyspieszenia obiektu korzystając z drugiego prawa dynamiki Newtona.\\
\bigskip
Będziemy potrzebować wzorów na zmianę prędkości i pokonaną drogę przez obiekt w danym odcinku czasu w ruchu jednostajnie przyśpieszonym prostoliniowym.
$$v_k = v_p + a\cdot t,$$ gdzie $v_k$ jest prędkością po wykonaniu kroku symulacji, $v_p$ jest prędkością początkową, $a$ oznacza przyśpieszenia, a $t$ to czas kroku symulacji.\\
Drugim wzorem jest:
$$s = v_p\cdot t + \frac{a\cdot t^2}{2},$$ gdzie $s$ oznacza drogą przebytą w jednym kroku, a pozostałe oznaczenia są identyczne jak powyżej.\\


Tak zdefiniowana symulacja N ciał spotyka się z następującymi problemami:
\begin{itemize}
\item Kiedy ciała są bardzo bliskie siebie, wtedy zadziała na nie ogromna siła, która w rzeczywistości będzie działała na ciało przez krótki czas. To znaczy krok symulacji może trwać znacznie dłużej niż czas, przez który obiekty będą blisko siebie. Przez to na ciało zadziała o wiele za duża siła niż powinna.
\item Ciało w pojedynczym kroku symulacji porusza się ruchem jednostajnie przyśpieszonym prostoliniowym, więc ruch w całej symulacji jest jedynie aproksymacją poprzez sklejenie ruchu obiektu w tych odcinkach czasu.
\end{itemize}

\section{\LARGE Naiwny algorytm symulacji N ciał}
\bigskip

\subsection{\Large Jednowątkowa wersja naiwnego algorytmu}

Każde ciało na początku symulacji ma pseudolosową pozycję, prędkość oraz masę. W mojej symulacji odległości są wyrażone w metrach, masy ciał są podane w kilogramach, a jednostką prędkości jest metr na sekundę. \\


Prosty pseudokod dla algorytmu symulującego problem N ciał może wyglądać następująco:\\
\bigskip
\lstset{
	backgroundcolor=\color{white},
	basicstyle=\footnotesize\fontfamily{fvm}\selectfont,
	numbers=left, 
	numbersep=8pt,	
	keywordstyle=\color{blue},
	commentstyle = \color{mygreen},
	literate=%
	%	zażółć gęślą jaźń
	{ź}{{\'z}}1
	{ż}{{\.z}}1
	{ń}{{\'n}}1
	{ó}{{\'o}}1
	{ł}{{\l{}}}1
	{ć}{{\'c}}1
	{ą}{{\k{a}}}1
	{ę}{{\k{e}}}1
	{ś}{{\'s}}1
}
\begin{lstlisting}[frame=single, framerule=2pt, caption=Pseudokod naiwnego algorytmu]
ustaw masę oraz początkową pozycję i prędkość dla każdego ciała
while(true):
  for i in {1...N}:
    for j in {1...N}:
      if (i!=j):
        Force[i] += SiłaPomiedzyCiałami(i, j) 
  for i in {1...N}:
    UaktualnijPozycjeCiała(i)
\end{lstlisting}

\bigskip

W liniach 3-6 tego algorytmu liczymy bezpośrednio siłę z jaką dwa ciała oddziałują na siebie dla każdej możliwej pary ciał. Jest to najbardziej kosztowna operacja w tym algorytmie, której złożoność to $\mathcal{O}(N^{2})$. W linii 7 uaktualniamy pozycję każdego ciała uwzględniając całkowitą siłę, która na nie działa. Siła ta wynika z powyżęj przytoczonego wzoru. \\

Nietrudno spostrzec że pojedyncza iteracja jednowątkowego naiwnego algorytu symulacji N ciał ma złożoność obliczeniową $\mathcal{O}(N^{2})$.


\subsection{\Large Zrównoleglenie naiwnego algorytmu}

Jednakże ten algorytm jest zbyt wolny dla dużej liczby ciał. W tym podrozdziale zoptymalizujemy go poprzez zrównoleglenie obliczeń. Wyliczenie siły oddziałującej na pewne ciało oraz analityczne wyznaczenie mu nowej pozycji są niezależne względem tych obliczeń dla pozostałych ciał. A to oznacza, że pojedynczy krok algorytmu możemy policzyć równolegle dla każdego obiektu.

\subsubsection{\large Architektura CUDA}
W tym celu wykorzystamy architekturę CUDA. 
Jest to uniwersalna architektura kart graficznych (które dzisiejszych czasach poza zastosowaniem w renderowaniu grafiki, są również często używane do masywnych obliczeń nawet na tysiącach wątków jednocześnie), umożliwiająca wykorzystanie ich mocy obliczeniowej w wielu problemach, które mogą się wykonywać zarówno sekwencyjne jak i wielowątkowo. Wykorzystałem CUDA w wersji v9.2.148 z compute capability 3.0 i wyżej. \\~\\
Wątki na CUDA są pogrupowane w bloki. W compute capability 3.0 każdy blok może mieć do 1024 wątków. Z kolei bloki są ułożone w gridzie, który może być nawet trójwymiarowy. W wymiarze X może być aż $2^{31}-1$ wątków, w dwóch pozostałych $65535$ \cite[str.~238-242]{Cuda}. Dodatkowo wątki są grupowane w mniejsze grupy niż bloki, zwane warpami, które liczą po 32 wątki. Wątki w jednym warpie są uruchamiane jednocześnie i zarządzane przez warp scheduler \cite[str.~70]{Cuda}.\\
\bigskip
Warto, także wspomnieć o podziale pamięci w programach pisanych w tej architekturze. \\Możemy wyróżnić trzy rodzaje pamięci :
\begin{itemize}
  \item lokalna - osobna dla każdego wątku, czyli wątki mogą mieć zmienne lokalne na swój użytek,
  \item współdzielona - pamięć dzielona przez wszystkie wątki w bloku(ale jest jej tylko 48kB \cite[str.~238-242]{Cuda}),
  \item globalna - najwolniejsza ze wszystkich rodzajów pamięci, ale wspólna dla wszystkich bloków.
\end{itemize}

\subsubsection{\large Thrust}
Thrust jest szablonową biblioteką dla CUDA bazująca na bibliotece STL z C++. Thrust umożliwia implementację aplikacji wielowątkowych za pośrednictwem interfejsu wysokiego poziomu, który jest w pełni zgodny z CUDA C. Korzystałem z wersji v9.2.148. \cite{thrust}


\subsubsection{\large Implementacja wielowątkowa}
W implementacji wykorzystuję dwie szablonowe struktury z biblioteki Thrust.
\textbf{host\_vector}\cite{thrust} jest odpowiednikiem \textbf{std::vector}. Rezyduje w pamięci hosta powiązanego z równoległym urządzeniem (ang. device). \textbf{device\_vector}\cite{thrust} różni się tym, że jest przechowywany w pamięci urządzenia. Implementacje podzielimy na dwie funkcje.\\
\bigskip

Funkcja NaiveSimBridge, przedstawiona w listingu 2, przyjmuje jako argument \textbf{host\_vector} z pozycjami wszystkich elementów symulacji, a następnie kopiuje go do \textbf{device\_vector} dla odowiedzialnego za transport pozycji ciał do pamięci urządzenia. \\Następnie w liniach 3-5 konwertuje \textbf{device\_vector} dla pozycji, prędkości i masy do raw pointerów. Wykorzystywane są w 6 linii, w której wywołujemy kernel NaiveSim. W potrójnych nawiasach specyfikujemy liczbę bloków oraz liczbę wątków w każdym bloku (jest to składnia z CUDA Runtime API \cite{runtimeApi}). 
W linii 7 kopiuje nowe pozycje z urządzenia do hosta. 
\bigskip
\lstset{backgroundcolor=\color{white}, basicstyle=\footnotesize\fontfamily{fvm}\selectfont, numbers=left, numbersep=8pt, keywordstyle=\color{blue},commentstyle = \color{mygreen}}\begin{lstlisting}[language=C++, frame=single, framerule=2pt, caption=Bridge pomiędzy główną pętlą a kernelem]
void NaiveSimBridge(host_vector &pos, int numberOfBodies, float dt) {
  thrust::device_vector<float> posD = pos;
  float *d_positions = thrust::raw_pointer_cast(posD.data());
  NaiveSim<<<numberOfBlocks, threadsPerBlock>>>(d_positions, 
  	d_velocities, d_weights, numberOfBodies, dt);
  pos = posD;
}
\end{lstlisting}
\bigskip
Kernelem nazywamy funkcję, którą możemy uruchomić dla wielu wątków w pamięci urządzenia. W tym przypadku kernel NaiveSim, ukazany w listingu 3, jest odpowiedzialny za wyznaczenie nowej pozycji dla każdego ciała. \\
\bigskip
W sygnaturze kernela widzimy, że przyjmuje trzy raw\_pointery do odpowiednio pozycji, prędkości oraz mas. A poza tym dostaje również  odcinek czasu, w którym wykonywany jest dany krok oraz całkowitą liczbę ciał w symulacji. W 6 linii wyznaczamy indeks obiektu, dla którego będziemy prowadzić obliczenia. Jako że korzystamy tylko z jednowymiarowego schematu bloków, to wystarczy wymnożyć identyfikator bloku z rozmiarem pojedynczego bloku oraz dodać identyfikator wątku w bloku. (W każdym kolejnym kernelu $thid$ będzie liczony tak samo).
W linii 7 mamy zabezpiecznie na wypadek gdyby obiekt o takim indeksie nie istniał, gdyż czasami liczba wywołanych wątków jest większa niz rzeczywista liczba obiektów. \\
\bigskip
Dalej mamy część, dla której równoleglimy nasz algorytm. Najpierw w liniach 12-23 mamy pętlę, w której liczymy siłę działającą na obiekt o identyfikatorze, który jest równy wcześniej wyliczonemu $thid$ poprzez każdy inny obiekt w symulacji. Postępujemy zgodnie ze wzorem z Prawa 4. W liniach 15-16 wyliczamy wektory odległości między naszym obiektem a każdym innym. W następnych dwóch liniach wyliczamy odległość między tymi dwoma obiektami i podnosimy ją do potęgi trzeciej, tak jak we wzorze. Z kolei w ostatnich liniach tej pętli podstawiamy wszystkie wartości do wzoru, aby obliczyć siłę działającą na ciało. \\
\bigskip
\lstset{backgroundcolor=\color{white}, basicstyle=\footnotesize\fontfamily{fvm}\selectfont, numbers=left, numbersep=8pt, keywordstyle=\color{blue},commentstyle = \color{mygreen}}\begin{lstlisting}[language=C++, frame=single, framerule=2pt, caption=Kernel NaiveSim]
const double G = 6.674 * (1e-11);
template <typename T>
__global__ void 
NaiveSim(T *pos, T *velo, T *weigh, int numberOfBodies, double dt) 
{
  int thid = blockIdx.x * blockDim.x + threadIdx.x;
  if(thid>=numberOfBodies) return;
  double pos[3] = {pos[thid*3], pos[thid*3+1], pos[thid*3+2]};
  double weighI = weigh[thid];
  double force[3] = {0.0, 0.0, 0.0};
  
  for j in {0..numberOfBodies-1}
  {
    if (j != thid) {
      double d[3];
      for(int k=0; k<3; k++) 
        d[k] = pos[j*3 + k] - pos[k];
      float dist = (d[0]*d[0] + d[1]*d[1] + d[2]*d[2]);
      dist = dist*sqrt(dist);
      float F = G * (weighI * weigh[j]);
      for(int k=0; k<3; k++)
        force[k] += F * d[k] / dist;	
    }
  }
  for k in {0..2}
  {
    float acc = force[k] / weighI;
    pos[thid*3+k] += velo[thid*3+k]*dt + acc*dt*dt/2;
    velo[thid*3+k] += acc*dt;
  }
}
\end{lstlisting}


Mając policzoną siłę oddziałującą na obiekt, przechodzimy do wyliczenia nowej pozycji dla obiektu. Jako, że ruch obiektu aproksymujemy poprzez przyjęcie, że obiekt w pojedynczym kroku porusza się ruchem jednostajnym przyśpieszonym, a następnie łączymy ze sobą kolejne kroki symulacji, to możemy w tym celu wykorzystać wcześniej wprowadzone wzory.\\ Najpierw w linii 25, korzystając z prawa 2, wyliczamy wektor przyśpieszenia ciała. W linii 26 do aktualnej pozycji dodajemy wektor drogi, o którą przesuwamy ciało po obecnym kroku. I w końcu, linia 27 aktualizuje wektor prędkości.\\
Wykorzystując architekturę CUDA, mogliśmy przyśpieszyć nasz algorytm. Jednakże, symulacja implementowana tym algorytmem ma jeszcze jeden duży problem. Tak jak wspomnieliśmy wcześniej, gdy obiekty są bardzo blisko siebie, to znaczy odległość między nimi jest bliska zeru, to wtedy siła, którą na siebie działają jest ogromna. Wtedy w naszej symulacji pojawiają się błędy, gdyż czas pojedynczej iteracji symulacji może być znacznie większy niż czas w rzeczywistości, przez który ciała są blisko siebie. 
\subsection{\Large Softening} 

Optymalizacją dla tego problemu jest, tak zwany \textbf{softening}\cite[str.~21]{Aarseth}. Polega na modyfikacji wzoru wprowadzonego w Prawie 4, do następującej postaci:
$$F_i = -G\cdot m_i \sum_{j=1, j\neq i}^N \frac{m_j\cdot (r_i - r_j)}{(|r_i - r_j|^2 + \epsilon^{2})^{\frac{3}{2}}},$$ 
gdzie wprowadzony $\epsilon$ ma za zadanie nie dopuścić do bardzo małych odległości w mianowniku wzoru. W pracy przyjąłem, że $\epsilon = 0.01$.

\subsection{\Large Złożoność zrównoleglonej naiwnej wersji algorytmu}
Równoległa wersja naiwnego algorytmu wciąż wykonuje pracę rzędu $\mathcal{O}(N^{2})$, jednakże dzięki temu, że dla każdego obiektu siły na niego działające oraz nową pozycję liczymy na osobnym wątku, to czas działania algorytmu to $\mathcal{O}(N)$, przy założeniu, że mamy do dyspozycji $N$ procesorów.

\section{\LARGE Równoległy algorytm Barnesa-Huta}
Zrównoleglony naiwny algorytm jest szybszy niż wersja jednowątkowa, jednakże wciąż jest zbyt wolny do symulacji układów z bardzo dużą liczbą ciał. W tym celu zaimplementujemy drugi algorytm, zwany algorytmem Barnesa-Huta \cite[str.~446-449]{barnhut}. Składa się on z dwóch części : tworzenia drzewa ósemkowego (ang. octree) oraz obliczania sił działających na ciało z wykorzystaniem stworzonych drzew.

\subsection{\Large Drzewa Ósemkowe}
Algorytm jest oparty na drzewach, a dokładniej drzewach ósemkowych \cite{octree}.
Struktura drzewa ósemkowego jest następująca(rys. Rysunek 1):
\begin{itemize}
  \item cała przestrzeń trójwymiarowa jest przedstawiana przez sześcian, który jest reprezentowany przez korzeń drzewa
  \item korzeń drzewa ma ośmioro następników, z których każdy reprezentuje jeden z ośmiu podsześcianów, na które dzielimy duży sześcian reprezentowany przez korzeń.
  \item drzewo składa się z węzłów wewnętrznych oraz liści
  \item jedynie liście drzewa zawierają punkty z symulacji
  \item drzewo ma ustaloną głębkość K
\end{itemize}

\begin{figure}
    \centering
    \def\svgwidth{\columnwidth}
    \input{tree.pdf_tex}
    \caption{Przykład drzewa ósemkowego (dla uproszczenia rysunku bez ustalonej głębokości) z czterema węzłami o następujących współrzędnych: (-0.5, -0.5, 0.5), (0.5, 0.5, 0.5), (-0.4, 0.4, -0.7), (-0.7, 0.6, -0.4) dla przestrzeni ograniczonej sześcianem o środku w punkcie (0, 0, 0) oraz boku równym 2
    }
\end{figure}
\subsection{\Large Kody Mortona}
Zanim pokażemy strukturę węzła w naszej implementacji drzewa ósemkowego, przytoczymy czym są kody Mortona, które będą niezbędnym narzędziem do ustalenia położenia węzłów w drzewie o ustalonej głębkości.\\
Kodami Mortona, nazywamy mapowanie punktu w przestrzeni do listy liczb(w naszym przypadku mapujemy punkty w 3-wymiarowej przestrzeni do liczb całkowitych, a konkretniej interesowć nas będzie ich bitowa reprezentacja).
Porządek Mortona jest definiowany przez \textbf{krzywą wypełniającą powierzchnie (ang. space-filling curve)}, która jest w kształcie litery $Z$, więc czasami jest nazywana \textbf{Z-krzywą}. Krzywa ta ma ważną własność - jeśli elementy są blisko siebie w drzewie, to w tym porządku ta bliskość jest zachowana w ułożeniu w pamięci. W pracy traktujemy kod Mortona jako 64-bitową liczbę całkowitą, w której $15$ bitów (łącznie $45$ dla wszystkich trzech wymiarów) oznacza kolejne rozgałęzienia dla naszego węzła, czyli jedną z dwóch części, w których punkt kolejno ląduje, gdy umieszczamy go w coraz mniejszych sześcianach, aż do przyjętej głębokości równej $15$ (czyli $K = 15$).

\begin{figure}[h]
    \centering      
    \def\svgscale{0.53}
    \input{zcurve3.pdf_tex}
    \caption{Przykład Z-curve}
    \label{fig:krzywa}
\end{figure}

\subsection{\Large Struktura węzła w drzewie ósemkowym}
Przedstawia się ona następująco: 
\lstset{backgroundcolor=\color{white}, basicstyle=\footnotesize\fontfamily{fvm}\selectfont, numbers=left, numbersep=8pt, keywordstyle=\color{blue},commentstyle = \color{mygreen}}              
\begin{lstlisting}[language=C++, frame=single, framerule=2pt, caption=Struktura OctreeNode]
struct OctreeNode {
  int children[8] = {-1, -1, -1, -1, -1, -1, -1, -1};
  int position = -1;
  std::vector<int> duplicates;
  float totalMass = 0.0;
  float centersOfMass[3] = {0.0, 0.0, 0.0};
};
\end{lstlisting}

W powyższej strukturze przechowujemy indeksy następników w globalnej tablicy węzłów.Mamy również pole position, które przyjmuje -1, gdy węzeł jest wewnętrzny oraz indeks węzła(na tablicę globalną), gdy węzeł jest liściem. Wektor $duplicates$ przechowuje w węźle indeksy wszystkich punktów o takim samym kodzie Mortona (czyli liści będzie tyle samo co unikatowych kodów Mortona stworzonych na bazie punktów wejściowych). Dodatkowo struktura węzła zawiera całkowitą masę poddrzewa oraz środek masy.\\

\textbf{Środek masy (barycentrum) ciała}  jest punktem w przestrzeni, który zachowuje się tak, jak gdyby w nim skupiona była cała masa układu ciał. Jest zadany następującym wzorem:
$$ x_{srm} = \frac{\sum_{j=1}^N m_j\cdot x_j}{\sum_{j=1}^N m_j},$$ gdzie $m_j$ oznacza masę $j$-tego ciała, $x_j$ oznacza jego $x$-ową współrzędną (dla dwóch pozostałych wzory są analogiczne). \\


\subsection{\Large Równoległa implementacja drzew ósemkowych}
Z wykorzystaniem powyżej zdefiniowanych kodów zaimplementujemy algorytm inspirowany algorytmem równoległego tworzenia drzewa ósemkowego wspomnianym w pracy Tero Karras'a \cite{tero}.

Zmodyfikowany algorytm (skrótowo) składa się z pięciu kroków :
\begin{itemize}
\item Obliczenie kodów Mortona dla każdego węzła. Realizujemy to poprzez kernel, który na podstawie przedziałów, w których zawierają się punkty w całym układzie dla każdego z wymiarów (znajdujemy dolną i górną granicę w każdym z wymiarów), wyznacza przez K poziomów coraz to dokładniejsze położenie poprzez ustawianie kolejnych bitów w liczbie binarnej. 
\item Sortujemy kody Mortona. W tym celu wykorzystujemy bibliotekę Thrust, a dokładniej funkcję \textbf{sort\_by\_key}. 
\item Kody liczymy do głębokości K, więc istnieje możliwość pojawienia się duplikatów, które musimy zachować. 
\item Liczymy ile wierzchołków będzie miało nasze drzewo (znamy jedynie liczbę liści, potrzebujemy policzyć również liczbę węzłów wewnętrznych). Dodatkowo tworzymy wszystkie wierzchołki w drzewie.
\item  Łączymy węzły według relacji (rodzic, dziecko). W tym celu musimy odpowiednio przyporządkować każdemu węzłowi jego węzeł nadrzędny.
\end{itemize}

\subsection{\Large Pseudokody poszczególnych kroków}
\subsubsection{\large Obliczanie kodów Mortona}
\lstset{backgroundcolor=\color{white}, basicstyle=\footnotesize\fontfamily{fvm}\selectfont, numbers=left, numbersep=8pt, keywordstyle=\color{blue},commentstyle = \color{mygreen}}              
\begin{lstlisting}[language=C++, frame=single, framerule=2pt, caption=Krok 1]
__global__
void calculateMortonCodes(T* pos, unsigned long long* codes, int numberOfBodies, T* mins, T* maxs) {
  float start[3] = {mins[0], mins[1], mins[2]};
  float middle[3] = {(maxs[0] - mins[0])/2, (maxs[1] - mins[1])/2, (maxs[2] - mins[2])/2};
  unsigned long long code = 0;
  for i in {0..K-1} 
  {
    for j in {0..2}
    {
      code <<= 1;
      if(start[j] + middle[j] < pos[3*thid + j]) 
      {
        code |= 0x1;
        start[j] += middle[j];
      }
      middle[j] /= 2;
    }
  }
  codes[thid] = code;
}
\end{lstlisting}
W przypadku obliczania kodów Mortona, potrzebujemy minimalnego oraz maksymalnego punktu w każdym z wymiarów (szukamy ich z pomocą funkcji minmax\_element() z biblioteki Thrust). Dzięki temu jesteśmy w stanie wyznaczyć początek oraz środek przedziału dla obiektu na danej głębkości. Poprzez to możemy stwierdzić, w której połowie znajduje się nasz obiekt(czyli na danej głębokości przydzielić mu 0 lub 1).

\subsubsection{\large Sortowanie kodów}
\lstset{backgroundcolor=\color{white}, basicstyle=\footnotesize\fontfamily{fvm}\selectfont, numbers=left, numbersep=8pt, keywordstyle=\color{blue},commentstyle = \color{mygreen}}              
\begin{lstlisting}[language=C++, frame=single, framerule=2pt, caption=Krok 2]
thrust::device_vector<int> sortedNodes(numberOfBodies);
int* d_sortedNodes = thrust::raw_pointer_cast(sortedNodes.data());
fillNodes<<<blocks, THREADS_PER_BLOCK>>>(d_sortedNodes, numberOfBodies);

thrust::sort_by_key(mortonCodes.begin(), mortonCodes.end(), sortedNodes.begin());  
\end{lstlisting}
\bigskip
Rolą wektora sortedNodes jest zachowanie początkowej numeracji punktów (początkowe indeksy wpisujemy do wektora sortedNodes poprzez kernel fillNodes w czasie stałym), to znaczy sortujemy pary \textbf{(kodMortona, początkowyIndeks)}.

\subsubsection{\large Obsługa zduplikowanych kodów Mortona}

\lstset{backgroundcolor=\color{white}, basicstyle=\footnotesize\fontfamily{fvm}\selectfont, numbers=left, numbersep=8pt, keywordstyle=\color{blue},commentstyle = \color{mygreen}}              
\begin{lstlisting}[language=C++, frame=single, framerule=2pt, caption=Krok 3]
thrust::device_vector<int> groups(numberOfBodies);
int* d_groups = thrust::raw_pointer_cast(groups.data());
computeDifferences<<<blocks, THREADS_PER_BLOCK>>>(d_codes, d_groups);
thrust::inclusive_scan(groups.begin(), groups.end(), groups.begin());
thrust::device_vector<int> first(numberOfBodies);
thrust::device_vector<int> last(numberOfBodies);
int* d_first = thrust::raw_pointer_cast(first.data());
int* d_last = thrust::raw_pointer_cast(last.data());
\end{lstlisting}
\bigskip
Wektor groups będzie przechowywał informację o indeksie grupy węzłów o tym samym kodzie Mortona. Obliczamy to poprzez połączenie kernela $computeDifferences$, który dla danej komórki $i$ stawia $1$ gdy $mortonCodes[i-1] \ne mortonCodes[i]$ , $0$ w przeciwnym przypadku (pierwsza komórka jest inicjowana na $0$). 
A następnie liczymy sumy prefiksowe na wektorze $groups$ w celu wyznaczenia indeksu każdej z grup. Następnie uruchmiamy, kernel $CalculateFirstAndLast$, który służy do wyznaczenia początku oraz końca przedziału w tablicy globalnej punktów dla każdego kodu Mortona (czyli dla każdej grupy). Kernel przedstawia się następująco:
\lstset{backgroundcolor=\color{white}, basicstyle=\footnotesize\fontfamily{fvm}\selectfont, numbers=left, numbersep=8pt, keywordstyle=\color{blue},commentstyle = \color{mygreen}}              
\begin{lstlisting}[language=C++, frame=single, framerule=2pt, caption=Kernel calculateFirstAndLast]
__global__
void calculateFirstAndLast(int* first, int* last, unsigned long long* codes, int numberOfBodies) {
    if (mortonCodes[thid-1] != mortonCodes[thid]) {
        last[group[thid-1]] = thid-1, first[group[thid]] = thid;
    }
}
\end{lstlisting}

Gdy już to policzymy to możemy stworzyć początkowe drzewo ósemkowe składające się tylko z liści.
\lstset{backgroundcolor=\color{white}, basicstyle=\footnotesize\fontfamily{fvm}\selectfont, numbers=left, numbersep=8pt, keywordstyle=\color{blue},commentstyle = \color{mygreen}}              
\begin{lstlisting}[language=C++, frame=single, framerule=2pt, caption=Stworzenie wektora octree]
thrust::device_vector<OctreeNode> octree(numberOfBodies);
OctreeNode* d_octree = thrust::raw_pointer_cast(uniquePointsCount);

AssignDuplicatesToNode<<<blocks, THREADS_PER_BLOCK>>>(octree, groups, first, last);
\end{lstlisting}
Po stworzeniu wektora reprezentującego drzewo przypisujemy każdemu węzłowi indeksy wszystkich punktów, które mają $i$-ty kod Mortona, czyli należą do $i$-tej grupy (kernel $AssignDuplicatesToNode$ wstawia je do wektora $duplicates$ odpowiedniego węzła z $octree$).
\subsubsection{\large Zliczanie węzłów wewnętrznych oraz łączenie węzłów}

W następnym kroku tworzymy wektor \textbf{parentsNumbers}, którego zadaniem jest przechowywanie informacji o rodzicu każdego z wezłów (informacja ta będzie niezbędna przy łączeniu wierzchołków) na każdym z poziomów (jak wspomnieliśmy nasze drzewo ma głębokość $K$). Poniższy fragment kodu zawiera również trzy istotne zmienne:
\begin{itemize}
\item \textbf{childrenCount} - zlicza liczbę nowych węzłów na każdym z poziomów drzewa,
\item \textbf{previousChildrenCount} - przechowuje liczbę węzłów z poprzedniego poziomu,
\item \textbf{allChildrenCount} - zlicza liczbę wszystkich węzłów w drzewie ósemkowym.
\end{itemize}

\lstset{backgroundcolor=\color{white}, basicstyle=\footnotesize\fontfamily{fvm}\selectfont, numbers=left, numbersep=8pt, keywordstyle=\color{blue},commentstyle = \color{mygreen}}              
\begin{lstlisting}[language=C++, frame=single, framerule=2pt, caption=Przechowywanie węzłów drzewa]
thrust::device_vector<int> parentsNumbers(uniquePointsCount);
int* d_parentsNumbers = thrust::raw_pointer_cast(parentsNumbers.data());

int childrenCount = uniquePointsCount;
int allChildrenCount = uniquePointsCount;
int previousChildrenCount = 0;
\end{lstlisting}

Kluczowym punktem tych dwóch części jest poniższa pętla. Iteruje się ona $K=15$ razy, zaczynając od dzieci drzewa (podejście \textbf{bottom-up}), oznacza to także, że zaczyna od węzłów ograniczających najmniejszy obszar, czyli obszaru ograniczającego nasze punkty najdokładniej.\\
W każdej z iteracji chcemy wyznaczyć rodziców dla węzłów. \\W tym celu pomocny jest kernel \textbf{calculateDuplicates} w połączeniu z \textbf{thrust::inclusive\_scan}, które pozwalają wyznaczyć duplikaty wśród rodziców(czyli węzły na wyższym poziomie, które mają identyczne kody Mortona, więc mają takie same następniki).
Kernel ustawia wartość $1$ w danej komórce wektora, jeśli rodzice dwóch kolejnych węzłów są różni (wystarczy sprawdzić dwa kolejne, gdyż dzięki sortowaniu dzieci każdego z węzłów są obok siebie), a następnie \textbf{inclusive\_scan} robi sumę prefiksową tej tablicy, aby wyznaczyć te, które są takie same(mają przypisane takie same liczby po obliczeniu sum prefiksowych).
\bigskip
\lstset{backgroundcolor=\color{white}, basicstyle=\footnotesize\fontfamily{fvm}\selectfont, numbers=left, numbersep=8pt, keywordstyle=\color{blue},commentstyle = \color{mygreen}}              
\begin{lstlisting}[language=C++, frame=single, framerule=2pt, caption=Kernel calculateDuplicates]
__global__
void calculateDuplicates(unsigned long long* mortonCodes, int* result, int N) {
  int thid = blockIdx.x*blockDim.x + threadIdx.x;
  if(thid >= N || thid == 0) return;
  unsigned long long code = mortonCodes[thid];
  unsigned long long previous_code = mortonCodes[thid-1];
  code >>= 3;
  previous_code >>= 3;
  result[thid] = (code != previous_code);
}

\end{lstlisting}
\bigskip
Po wyznaczeniu nowych wierzchołków na kolejnym poziomie, wstawiamy je do wektora \textbf{octree}, a następnie przesuwamy im indeks, aby miały indeksy zaczynające się od pierwszego wolnego (po ostatnim węźle z niższego poziomu). Widzimy, że tym sposobem \textbf{root} drzewa będzie ostatnim węzłem w naszej tablicy.

Kiedy stworzymy węzły na danym poziomie, to następnym zadaniem jest połączenie ich z węzłami będącymi na niższym poziomie. Relizujemy to poprzez kernel \textbf{connectChildren}.\\
\bigskip
Dodatkowo w tym kernelu nie liczymy całkowicie środka masy dla punktów, a jedynie liczniki ze wzoru, czyli sumę iloczynów mas i pozycji ciał w układzie. W celu dokończenia wyznaczania barycentrum po utworzeniu całego drzewa, odpalamy kernel, który dla każdego z węzłów podzielimy obecne środki mas przez $totalMass$ (które również wyliczyliśmy).
\bigskip
\lstset{backgroundcolor=\color{white}, basicstyle=\footnotesize\fontfamily{fvm}\selectfont, numbers=left, numbersep=8pt, keywordstyle=\color{blue},commentstyle = \color{mygreen}}              
\begin{lstlisting}[language=C++, frame=single, framerule=2pt, caption=Kernel connectChildren]
__global__
void connectChildren(unsigned long long int* mortonCodes, int* parentsNumbers, OctreeNode* octree, 
    int N, int previousChildrenCount, int* sortedNodes, double* pos, double* wei, int level) 
{
    unsigned long long int childNumber = mortonCodes[thid]&0x7; 
    octree[parentsNumbers[thid]].children[childNumber] = thid+previousChildrenCount;
    octree[parentsNumbers[thid]].position = -1;
    octree[thid+previousChildrenCount].position = level == 0 ? sortedNodes[thid] : -1;
    int childId = sortedNodes[thid];
    if(level == 0) {
        octree[thid].totalMass = wei[childId];
        for k in {0..2} 
        {
            octree[thid].centersOfMass[k] = (wei[childId] * pos[3*childId + k]) / wei[childId];
        }
    }
    int pthid = parentsNumbers[thid];
    atomicAdd(&octree[pthid].totalMass, octree[thid+previousChildrenCount].totalMass);
    for k in {0..2}:
    {
    	atomicAdd(&octree[pthid].centersOfMass[k], 
    		octree[thid+previousChildrenCount].centersOfMass[k]);
    }
}
\end{lstlisting}

Cele, które ten kernel realizuje, są następujące:
\begin{itemize}
\item ustawienie odpowiedniego dziecka dla rodzica(informacja z kodu Mortona),
\item ustawienie pola position, to znaczy -1 gdy węzeł wewnętrzny, w przeciwnym przypadku identyfikator węzła,
\item aktualizacja totalMass oraz centersOfMass dla węzła,
\item dodatkowo, gdy funkcja przetwarza liście drzewa, to ustawia im początkowe wartości dla totalMass oraz centersOfMass.
\end{itemize}

Całą pętlę realizującą kroki piąty oraz szósty, przedstawia pseudokod w listingu 13.
\lstset{backgroundcolor=\color{white}, basicstyle=\footnotesize\fontfamily{fvm}\selectfont, numbers=left, numbersep=8pt, keywordstyle=\color{blue},commentstyle = \color{mygreen}}              
\begin{lstlisting}[language=C++, frame=single, framerule=2pt, caption=Kroki 4-5]
for(int i = 0; i < K; ++i) {
    blocks = (childrenCount+THREADS_PER_BLOCK-1)/THREADS_PER_BLOCK;
    thrust::fill(parentsNumbers.begin(), parentsNumbers.end(), 0);
    calculateDuplicates<<<blocks, THREADS_PER_BLOCK>>>(
        d_codes,
        d_parentsNumbers,
        childrenCount
    );
        
    thrust::inclusive_scan(parentsNumbers.begin(), parentsNumbers.end(), parentsNumbers.begin());
    octree.insert(octree.end(), parentsNumbers[childrenCount-1]+1, OctreeNode());
    d_octree = thrust::raw_pointer_cast(octree.data());
        
    thrust::for_each(parentsNumbers.begin(), parentsNumbers.end(),
    	thrust::placeholders::_1 += allChildrenCount);
        
    connectChildren<<<blocks, THREADS_PER_BLOCK>>>(
        d_codes,
        d_parentsNumbers,
        d_octree,
        childrenCount,
        previousChildrenCount,
        d_sortedNodes,
        d_positions,
        d_weights,
        i
    );

    thrust::for_each(mortonCodes.begin(), mortonCodes.end(), thrust::placeholders::_1 >>= 3);        
    auto it = thrust::unique(mortonCodes.begin(), mortonCodes.end());
    mortonCodes.erase(it, mortonCodes.end());
    d_codes = thrust::raw_pointer_cast(mortonCodes.data()); 
    childrenCount = thrust::distance(mortonCodes.begin(), it);
    previousChildrenCount = allChildrenCount;
    allChildrenCount += childrenCount;
}
\end{lstlisting}
\subsection{\Large Złożoność budowania drzewa}
Przyjrzyjmy się kolejnym operacjom w naszym algorytmie. Krok pierwszy wykonujemy w czasie stałym. Następnie sortowanie z biblioteki thrust, które wykonuje sie poprzez równoległy radixsort, czyli ma złożoność obliczeniową $\mathcal{O}(log_{N})$. Krok trzeci również wykonuje się logarytmicznie, a jego operacją dominującą jest thrust::inclusive\_scan. Ostatnia część jest bardziej wymagająca czasowo, gdyż ma złożoność obliczeniową $\mathcal{O}(K\cdot log_{N})$.
Czyli widzimy, żę jest operacją dominującą całego algorymu. Z tego wynika, że złożoność algorytmu budowania drzewa, to $\mathcal{O}(K\cdot log_{N})$, gdzie w naszej symulacji $K=15$.
\section{\LARGE Obliczanie sił oddziałujących na ciało}

Drzewo zostało stworzone w celu szybszego obliczania siły jaka działa na ciało.\\
Wersje jednowątkowa oraz wielowątkowa algorytmu obliczania siły różnią się jedynie tym, że ta druga robi to na osobnym wątku dla każdego ciała. Dodatkowowo zaimplementowałem ją iteracyjnie.\\
\bigskip
Algorytm polega na przejściu drzewa od korzenia i na sprawdzaniu czy węzeł jest wewnętrzny czy zewnętrzny. Gdy węzeł jest liściem, to liczymy siłę między naszym punktem a wszystkim punktami z wektora $duplicates$ (może być ich więcej niż jeden przez duplikaty w kodach Mortona). Każdą z sił oddziałujących na punkt liczymy identycznie jak w naiwnym algorytmie. Gdy węzeł jest wewnętrzny, to postępujemy następująco:\\
\bigskip
Niech s będzie szerokością obszaru obejmowanego przez sześcian oraz niech d będzie odległością między środkiem masy obszaru a punktem. Jeśli $s/d < \theta$, gdzie przyjęliśmy, że $\theta = 2.0$, to liczymy siłę między środkiem masy obszaru a punktem. W przeciwnym przypadku wywołujemy się rekurencyjnie na ośmiu podsześcianach. Ogólnie, im $\theta$ jest większa, to obliczenia są mniej dokładne, czyli więcej poddrzew traktujemy jako jeden węzeł \cite{Aarseth}.\\
\bigskip
Dodatkowo musimy rostrzygać czy nasz punkt i przetwarzany węzeł nie są tym samym węzłem, aby nie liczyć siły między nimi.\\~\\
W poniższej iteracyjnej implementacji algorytmu obliczania siły korzystamy z dwóch tablic, które będzie nam symulować stos. Gdy przetwarzamy jeden wierzchołek i okazało się, że musimy w rekurencyjnej wersji wywoływalibyśmy się rekurencyjnie na mniejszym obszarze, tutaj wrzucimy na stos dwie pary. Pierwszą będzie \textbf{(idObecnegoWęzła, nrDziecka+1)}, czyli po przetworzeniu całego poddrzewa dziecka o  nrDziecka, przejdziemy do przetwarzania kolejnego dziecka. Druga para to \textbf{(idDziecka, 0)}, czyli wrzucamy na stos pierwszego dziecko obecnego węzła (to znaczy węzeł na którym będziemy wywoływać się rekurencyjnie).\\
\bigskip
Z kolei w celu przechowywania granic wyznaczających obszar, który ogranicza dany węzeł trzymamy jedynie tablice z minimalnymi i maksymalnymi punktami w każdym z wymiarów dla korzenia. Następnie, gdy jesteśmy na poziomie $i$, to dzielimy długość boku sześcianu korzenia przez $2^{i}$, co pozwala nam uzyskać bok węzła na poziomie $i$.

\newpage
\lstset{backgroundcolor=\color{white}, basicstyle=\footnotesize\fontfamily{fvm}\selectfont, numbers=left, numbersep=8pt, keywordstyle=\color{blue},commentstyle = \color{mygreen}} 
\begin{lstlisting}[language=C++, frame=single, framerule=2pt, caption=Obliczanie siły oddziałującej na ciało w układzie]
__global__
void computeForces(OctreeNode* octree, double* velocities, double* weights, 
    double* pos, double* mins, double* maxs, int AllNodes, int N, double dt) 
{	
    float forces[3] = {0.0, 0.0, 0.0};
    float p = {pos[3*thid], pos[3*thid + 1], pos[3*thid + 2]);
    unsigned int stack[16], child[16];
    float widthCube = maxs[0]-mins[0];
    int top = -1;
    stack[++top] = AllNodes - 1, child[top] = 0;

    while(top>=0) 
    {
    	int prevTop = top, nextChild = child[top], idx = stack[top--];
        if(idx == -1) continue;
        
        if(octree[idx].position == -1) {
            double d = distanceBetween(octree[idx].centerOfMass(), p);
            double s = widthCube/(1<<prevTop);
            bool isFarAway = (s/d < theta);
            if(isFarAway) {
            	forces += computeForcesBetween(octree[idx].centerOfMass, p);
            }
            else {
                if(nextChild==numberOfChilds) continue;
                stack[++top] = idx, child[top] = nextChild + 1;
                stack[++top] = octree[idx].children[nextChild], child[top] = 0;
            }
        } 
        else {
       	    if(thid == octree[idx].position) continue;
       	    	for point in octree[idx].duplicates
                    forces += computeForcesBetween(octree[idx].getPoint(point), p);	
        }
    }    
    UpdatePositionAndVelocity(forces, positions, velocities, weights, N, dt);
}
\end{lstlisting}

\subsection{Złożoność algorytmu obliczania siły}
Złożoność obliczeniowa algorytmu obliczania siły przy równomiernym rozkładzie punktów wynosi $\mathcal{O}(log_{N})$ i zostało to pokazane w pracy wprowadzającej algorytm Barnesa-Huta \cite{barnhut}.

\section{\LARGE Wizualizacja}
	
W celu wizualizacji symulacji wykorzystałem OpenGL3. 

\subsection{\large OpenGL}
OpenGL \cite{opengl} jest API, które jest przeznaczone głównie do tworzenia grafiki. OpenGL zazwyczaj wykorzystuje kartę graficzną (GPU), więc tworzenie grafiki następuje szybciej niż innymi sposobami. Ten efekt nazywamy przyspieszeniem sprzętowym. OpenGL wykorzystywany jest często przez gry komputerowe i wygaszacze ekranu.

\subsection{\large Renderowanie symulacji}

Najistotniejszym punktem kodu OpenGL-owego jest rysowanie symulacji w każdym kroku, za które odpowiada funkcja \textbf{Render}:
\lstset{backgroundcolor=\color{white}, basicstyle=\footnotesize\fontfamily{fvm}\selectfont, numbers=left, numbersep=8pt, keywordstyle=\color{blue},commentstyle = \color{mygreen}}              
\begin{lstlisting}[language=C++, frame=single, framerule=2pt, caption=Pseudokod renderowania symulacji]
void Render() 
{
    glUseProgram(program);
    glm::mat4 view = glm::lookAt(
        glm::vec3(
        camera_radius*sin(camera_theta),
        camera_radius*cos(camera_theta)*cos(camera_phi),
        camera_radius*cos(camera_theta)*sin(camera_phi)
        ),
        glm::vec3(0, 0, 0),
        glm::vec3(0, 1, 0)
    );
    glm::mat4 projection = glm::perspective(
        glm::radians(45.0f),
        1.0f*width/height,
        0.1f,
        100.0f
    );
    glm::mat4 mvp = projection * view;
    GLuint MatrixID = glGetUniformLocation(program, "MVP");
    glUniformMatrix4fv(MatrixID, 1, GL_FALSE, &mvp[0][0]);
    
    UpdateBuffers();
    DrawPoints();
}
\end{lstlisting}
\bigskip

Render polega głównie na wykorzystaniu macierzy Model-View-Projection (MVP) \cite{tutMat}. 
W linii 19 wymnażamy wszystkie macierze ze sobą (pojedyncza macierz odpowiada za jeden krok MVP), uzyskując wyrenderowaną pozycję naszych obiektów).\\

Bardziej szczegółowo, najpierw ustawiamy kamerę, do czego służy funkcja \textbf{lookAt} \cite{opengl}, która jako pierwszy argument przyjmuje współrzędne kamery, następnie punkt na który patrzymy, a w ostatnim parametrze ustawiamy, że patrzymy z góry do dołu.\\
Z kolei funkcja \textbf{perspective} \cite{opengl} odpowiada za rzutowanie, a w argumentach przyjmuje:
\begin{itemize}
\item kąt z jakiego patrzymy na punkt podany w radianach
\item \textbf{aspect ratio}, czyli proporcje pomiędzy szerokością i wysokością obrazu
\item \textbf{far clipping plane} oraz \textbf{near clipping plane}, które wyznaczają płaszczyzny, które ograniczają obszar renderowania
\end{itemize} 

\newpage

\section{\LARGE Podsumowanie}

W pracy zaimplementowałem cztery algorytmy:
\begin{itemize}
\item Jednowątkowy naiwny algorytm 
\item Wielowątkowy naiwny algorytm 
\item Jednowątkowy algorytm Barnesa-Huta
\item Wielowątkowy algorytm Barnesa-Huta
\end{itemize}

Symulacje, których wyniki zostały zebrane w poniższych wykresach były uruchamiane na karcie NVIDIA GeForce GTX 980. Poniżej przedstawię wykresy przedstawiające wyniki moich implementacji algorytmów wielowątkowych z powyższej listy. Algorytmy 1 i 3 zostały wykorzystane jedynie do testowania poprawności symulacji. \\
Dane testowe były losowe o równomiernym rozkładzie. Losowane były początkowe:
\begin{itemize}
\item pozycje ciał w przedziale $\{-1.0, 1.0\}$,
\item prędkości ciał w przedziale $\{-0.01, 0.01\}$,
\item masy ciał w przedziale $\{1000.0, 100000.0\}$.
\end{itemize}

\begin{figure}[h]
\begin{tikzpicture}
\begin{axis}[
    title={Porównanie czasu działania algorytmów},
    xlabel={Liczba ciał},
    ylabel={Średni czas kroku(s)},
    xmin=0, xmax=100000,
    ymin=0, ymax=0.6,
    legend pos=north west,
    ymajorgrids=true,
    grid style=dashed,
    scaled x ticks=false,
    width=0.8\textwidth,
    xtick distance=20000,
]
\addplot[
    color=red,
    mark=square,
    ]
    coordinates {
    (100,0.00826626)(3000,0.021987)(7000,0.0480744)(11000,0.0442917)(15000,0.0429789)(19000,0.0436969)(23000,0.0452354)(27000,0.049968)(31000,0.0521729)(35000,0.0498652)(39000,0.0540352)(43000,0.0584782)(47000,0.053342)(51000,0.0531557)(55000,0.0546283)(59000,0.0703022)(63000,0.0551174)(67000,0.0989813)(71000,0.0693708)(75000,0.0669189)(79000,0.104832)(83000,0.0702073)(85000,0.0853074)(91000,0.087911)(95000,0.0727809)(99000,0.0826717)
    };
\addplot[
    color=blue,
    mark=square,
    ]
    coordinates {
    (100,0.0001472)(3000,0.0028682)(5000,0.00483034)(7000,0.00709195)(9000,0.00980842)(11000,0.0131749)
(15000,0.0205186)(19000,0.0315434)(23000,0.0387652)(27000,0.0480237)
(31000,0.0580048)(33000,0.0851563)(35000,0.0945012)(37000,0.103412)
(45000,0.142862)(53000,0.178091)(57000,0.195938)(59000,0.206165)
(63000,0.228704)(65000,0.239777)(67000,0.300484)(71000,0.328274)
(75000,0.360973)(79000,0.391146)(81000,0.406964)(85000,0.439855)
(89000,0.48233)(93000,0.511687)(99000,0.55421)
    };
\legend{Wielowątkowy iteracyjny Barnesa-Huta, Wielowątkowy naiwny algorytm}
\end{axis}
\end{tikzpicture}
\caption{Porównanie czasu działania algorytmów}
\end{figure}


Powyżej widać wykres przedstawiający czas wykonywania się poszczególnych algorytmów przy jednakowych danych wejściowych oraz przez identyczną liczbę kroków. W testach algorytmy były uruchamiane przez $500$ kroków, a następnie całkowity czas działania algorytmu był dzielony przez liczbę kroków. Wykres przedstawia czasy działania obu algorytmów równoległych dla wybranych liczby obiektów z zakresu $\{0,100000\}$.

Zauważmy że dla coraz większej liczby ciał, równoległa implementacja algorytmu Barnesa-Huta jest o wiele szybsza niż wielowątkowy algorytm liczący dla każdego ciała siłę działającą na niego przez każde inne ciało. \\
Zachodzi również zależność, że im więcej tur, tym algorytm Barnesa-Huta spisuje się lepiej, gdyż część obiektów oddala się względem innych obiektów i przez to często grupka obiektów jest traktowana jako jeden obiekt i nie musimy liczyć siły z każdym ciałem z osobna, a za to liczymy siłę tylko raz z środkiem masy tej grupki ciał.\\
Widzimy to na drugim wykresie, gdzie mamy ustalone, że ciał w symulacji jest $1000$, a zmienna jest liczba symulowanych kroków.
\begin{figure}[h]
\begin{tikzpicture}
\begin{axis}[
    title={Porównanie czasu działania algorytmów},
    xlabel={Liczba kroków w symulacji},
    ylabel={Średni czas kroku(s)},
    xmin=0, xmax=9200,
    ymin=0, ymax=0.04,
    legend pos=north west,
    ymajorgrids=true,
    grid style=dashed,
    scaled x ticks=false,
    scaled y ticks=false,
    width=0.8\textwidth,
    xtick distance=2000,
    ytick distance=0.01,
]
\addplot[
    color=red,
    mark=square,
    ]
    coordinates {
    (100,0.0149154)(600,0.0154447)(1100,0.0236453)(1600,0.0316999)
(2100,0.0194703)(2600,0.0168979)(3100,0.0156088)(3600,0.0145503)
(4100,0.0135125)(4600,0.013297)(5100,0.0130355)(5600,0.0126095)
(6100,0.0127521)(6600,0.0122871)(7100,0.0117973)(7600,0.0113905)
(8100,0.0114501)(8600,0.0115139)(9100,0.0113336)
    };
\legend{Wielowątkowy Barnesa-Huta}
\end{axis}
\end{tikzpicture}
\caption{Porównanie czasu działania algorytmów}
\end{figure}

Przeprowadzone eksperymenty dowodzą wysokiej przydatności architektury CUDA w implementacji algorytmu naiwnego oraz algorytmu Barnesa-Huta dla symulacji N ciał.
\newpage
\nocite{*}
\printbibliography%[title=\foreignlanguage{polski}{Bibliografia}]

\end
{document}
